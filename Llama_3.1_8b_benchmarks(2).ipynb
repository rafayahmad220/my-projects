{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ee9785c5854142d7933dbfd9ac142f2e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77e4c612921f491786af7a215c2e596e","IPY_MODEL_2c9882eee9be4f7ba63345a53840acd6","IPY_MODEL_0816a47c2c464602af3d53b21440c186"],"layout":"IPY_MODEL_32e8d05cf71b4465b34691857a7eeebb"}},"77e4c612921f491786af7a215c2e596e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d220c5b9bf524503937720bd21572fa7","placeholder":"​","style":"IPY_MODEL_5cc168454a564154aa6343cd539e5436","value":"config.json: 100%"}},"2c9882eee9be4f7ba63345a53840acd6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8d03a3b8d7940b8b1f728c5f1352517","max":826,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec5e34fd788e448f9cd7d6b2618b618e","value":826}},"0816a47c2c464602af3d53b21440c186":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b096b0270d845ab98e855cdf66d0416","placeholder":"​","style":"IPY_MODEL_5e3c8328a0034d9fac096aafdabc0823","value":" 826/826 [00:00&lt;00:00, 52.1kB/s]"}},"32e8d05cf71b4465b34691857a7eeebb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d220c5b9bf524503937720bd21572fa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cc168454a564154aa6343cd539e5436":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8d03a3b8d7940b8b1f728c5f1352517":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec5e34fd788e448f9cd7d6b2618b618e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5b096b0270d845ab98e855cdf66d0416":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e3c8328a0034d9fac096aafdabc0823":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76ebeb1ea40a4d279357684e3256ad82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84714dac019d4c2ebce66e1dd0bb7aec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d093a71ade5745eb82eefbb46341e69f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5ac70e3860146cb9b29d587fcf476af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d2dcbfa6a194d91832b019143635f29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36cbc3e4f5e641faa092a5db2fb8dca2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b129be6bf9f4c39bbc5c34a3d0b6c79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d093a71ade5745eb82eefbb46341e69f","placeholder":"​","style":"IPY_MODEL_f5ac70e3860146cb9b29d587fcf476af","value":"model.safetensors.index.json: 100%"}},"275d0d217aa7446482c55c80adec33d1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76ebeb1ea40a4d279357684e3256ad82","max":23950,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84714dac019d4c2ebce66e1dd0bb7aec","value":23950}},"c16b6b31f57a495fae648bffaebe1ab8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d2dcbfa6a194d91832b019143635f29","placeholder":"​","style":"IPY_MODEL_36cbc3e4f5e641faa092a5db2fb8dca2","value":" 23.9k/23.9k [00:00&lt;00:00, 1.55MB/s]"}},"1b11229b81264628ae7b1ff1519cf1a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b9689cce3d34fa99d1fac6ac5878670":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b129be6bf9f4c39bbc5c34a3d0b6c79","IPY_MODEL_275d0d217aa7446482c55c80adec33d1","IPY_MODEL_c16b6b31f57a495fae648bffaebe1ab8"],"layout":"IPY_MODEL_1b11229b81264628ae7b1ff1519cf1a5"}},"f56246c9167a419d8b8fc95b98a1e1b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e06819eb98e34ec0b60948622808ad84":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"634e8431341e4a58bfbe36c7e89fb35c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a86067244004bd6b21abb9e49b71372":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cdfc7d424854bf18d1f692503e04a81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fece3a4097f74a2cbc7b5693998f1d6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"454e544864144b33b68d92a46ca3f9c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_634e8431341e4a58bfbe36c7e89fb35c","placeholder":"​","style":"IPY_MODEL_5a86067244004bd6b21abb9e49b71372","value":"Downloading shards: 100%"}},"9073c10462684a4ca1c6a1cc2a91348a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f56246c9167a419d8b8fc95b98a1e1b5","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e06819eb98e34ec0b60948622808ad84","value":4}},"22d30563341d4d0cb34cee9859fe3513":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cdfc7d424854bf18d1f692503e04a81","placeholder":"​","style":"IPY_MODEL_fece3a4097f74a2cbc7b5693998f1d6c","value":" 4/4 [01:19&lt;00:00, 17.06s/it]"}},"66c3578e93d54a2cbe1a07472b658fa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c1249e4851243df837526f140567ade":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_454e544864144b33b68d92a46ca3f9c3","IPY_MODEL_9073c10462684a4ca1c6a1cc2a91348a","IPY_MODEL_22d30563341d4d0cb34cee9859fe3513"],"layout":"IPY_MODEL_66c3578e93d54a2cbe1a07472b658fa6"}},"781f570d5b9d4c829573f21159ef7298":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5b5ff5f367d493fb14656c0cb570a6e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"80400f3c1881436f911240a97ab02de3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73e5debc1d5c4af0bff6982d46aec803":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cbe30ca483294239ac26ab65f528fd68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6e3dfd797664e3aae8802a99277fb2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d49ef38528774710bfd601053a2619a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80400f3c1881436f911240a97ab02de3","placeholder":"​","style":"IPY_MODEL_73e5debc1d5c4af0bff6982d46aec803","value":"model-00001-of-00004.safetensors: 100%"}},"f30db82fd312415a83c1f25d94cd5520":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_781f570d5b9d4c829573f21159ef7298","max":4976698672,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a5b5ff5f367d493fb14656c0cb570a6e","value":4976698672}},"c37cba18726a4a5eb8841dab8ee704ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbe30ca483294239ac26ab65f528fd68","placeholder":"​","style":"IPY_MODEL_d6e3dfd797664e3aae8802a99277fb2f","value":" 4.98G/4.98G [00:24&lt;00:00, 265MB/s]"}},"b53a008e70ca402d8b444f6e9538d593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e5841ae1f2d43b181cdac88f823d864":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d49ef38528774710bfd601053a2619a3","IPY_MODEL_f30db82fd312415a83c1f25d94cd5520","IPY_MODEL_c37cba18726a4a5eb8841dab8ee704ce"],"layout":"IPY_MODEL_b53a008e70ca402d8b444f6e9538d593"}},"7e97afbe064c4107827bff7a83ee23af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8cd787abbf5472aa67343f1728c52be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b98a14487fa54be6b21cb98710f0236e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ae4c9fc31e24444ad8fde69774ef4d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f4f85e7258641738744a47cc7830ab1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ca36631b7de4214816e8de83f62bd54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f072af7153944ba82b063eefe35649c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b98a14487fa54be6b21cb98710f0236e","placeholder":"​","style":"IPY_MODEL_2ae4c9fc31e24444ad8fde69774ef4d6","value":"model-00002-of-00004.safetensors: 100%"}},"84cf6a8f366a4209bb131f15dc43f873":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e97afbe064c4107827bff7a83ee23af","max":4999802720,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8cd787abbf5472aa67343f1728c52be","value":4999802720}},"aa33e97e580d4a6a9e2dac4fd0650e3a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f4f85e7258641738744a47cc7830ab1","placeholder":"​","style":"IPY_MODEL_7ca36631b7de4214816e8de83f62bd54","value":" 5.00G/5.00G [00:23&lt;00:00, 106MB/s]"}},"574ff011085b47c79bc013db6124f126":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a918b0a9b38c4beda735c4428b7010d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f072af7153944ba82b063eefe35649c","IPY_MODEL_84cf6a8f366a4209bb131f15dc43f873","IPY_MODEL_aa33e97e580d4a6a9e2dac4fd0650e3a"],"layout":"IPY_MODEL_574ff011085b47c79bc013db6124f126"}},"4d3d09eaed5c45ba84863cdc5d4d0d6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63ca1f8e6cb94d8b865c74ced85861c7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"011b3613800e43cbaf638e8e6a583bd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c96dd120454c44fcafee1552273bbbed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62b70c7b9e1340a0afe4b4bbffffcc1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a50dc563ffa4d9ebe48f0ad247bf120":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2e7ed8d29b147cbafde42fff242d6eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_011b3613800e43cbaf638e8e6a583bd8","placeholder":"​","style":"IPY_MODEL_c96dd120454c44fcafee1552273bbbed","value":"model-00003-of-00004.safetensors: 100%"}},"4acf7c65d83040a7badda4f9d3fbc67d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d3d09eaed5c45ba84863cdc5d4d0d6c","max":4915916176,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63ca1f8e6cb94d8b865c74ced85861c7","value":4915916176}},"87bc1eebc7d04e61b5f3ebe9087a07ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62b70c7b9e1340a0afe4b4bbffffcc1a","placeholder":"​","style":"IPY_MODEL_4a50dc563ffa4d9ebe48f0ad247bf120","value":" 4.92G/4.92G [00:26&lt;00:00, 309MB/s]"}},"d0f821e23a0a47b3bb94938a0648f433":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f398c252e2794c9b98641af5f0e4ee9c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c2e7ed8d29b147cbafde42fff242d6eb","IPY_MODEL_4acf7c65d83040a7badda4f9d3fbc67d","IPY_MODEL_87bc1eebc7d04e61b5f3ebe9087a07ec"],"layout":"IPY_MODEL_d0f821e23a0a47b3bb94938a0648f433"}},"bc58e71ae35b488499f065323cb1fe29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ceac8cd1f884506bf7ca1d33552f544":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14de3ab8a7494fd1bcf859c3e4175608":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04853163ef624248b3f57568861a21cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6024583c2dbc4c08a0a0c04fa060d048":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a13efa683c843598fa744ce58cb12f7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65ae181635274d4c880e934a3a0a4408":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14de3ab8a7494fd1bcf859c3e4175608","placeholder":"​","style":"IPY_MODEL_04853163ef624248b3f57568861a21cb","value":"model-00004-of-00004.safetensors: 100%"}},"fb34fe6fc6bc4f84a0f59f66a47721ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc58e71ae35b488499f065323cb1fe29","max":1168138808,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9ceac8cd1f884506bf7ca1d33552f544","value":1168138808}},"a2c56562202c46ce9432a36239ecdcae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6024583c2dbc4c08a0a0c04fa060d048","placeholder":"​","style":"IPY_MODEL_9a13efa683c843598fa744ce58cb12f7","value":" 1.17G/1.17G [00:04&lt;00:00, 239MB/s]"}},"b2c59a1f051c409d9d6253347eb95250":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fcad3a172ef44bdb92c023116629f1d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65ae181635274d4c880e934a3a0a4408","IPY_MODEL_fb34fe6fc6bc4f84a0f59f66a47721ad","IPY_MODEL_a2c56562202c46ce9432a36239ecdcae"],"layout":"IPY_MODEL_b2c59a1f051c409d9d6253347eb95250"}},"1a22ba937b814709a4aa650cea645336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73de0d9cbb1046409fbfbdf54067e6a3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8158b8d7e1ea4965aa58e1b52e73c54d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"583edc9ad23046f5a5f82412b45390d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43eba5723e8f492e964d97b0ed11dbb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb35822cc9ad4264b5ffce02e1decd1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"caf5f164cd6d4376b2385e1d3d55a1c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8158b8d7e1ea4965aa58e1b52e73c54d","placeholder":"​","style":"IPY_MODEL_583edc9ad23046f5a5f82412b45390d4","value":"Loading checkpoint shards:  25%"}},"9df350b54a06477eb7713e39158317bb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a22ba937b814709a4aa650cea645336","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73de0d9cbb1046409fbfbdf54067e6a3","value":1}},"090391f6875240969315c0de70c0c047":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43eba5723e8f492e964d97b0ed11dbb0","placeholder":"​","style":"IPY_MODEL_fb35822cc9ad4264b5ffce02e1decd1e","value":" 1/4 [00:22&lt;01:08, 22.97s/it]"}},"3664acc6a0d8451a8fcbaeb71befc9f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b1e3fd229814ec9a66904fa8075e58e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_caf5f164cd6d4376b2385e1d3d55a1c5","IPY_MODEL_9df350b54a06477eb7713e39158317bb","IPY_MODEL_090391f6875240969315c0de70c0c047"],"layout":"IPY_MODEL_3664acc6a0d8451a8fcbaeb71befc9f5"}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade transformers>=4.28","metadata":{"id":"pWdh2wZ6G07r","execution":{"iopub.status.busy":"2024-08-25T17:19:12.865283Z","iopub.execute_input":"2024-08-25T17:19:12.865575Z","iopub.status.idle":"2024-08-25T17:19:37.466596Z","shell.execute_reply.started":"2024-08-25T17:19:12.865536Z","shell.execute_reply":"2024-08-25T17:19:37.465444Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install sentencepiece","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:19:37.468445Z","iopub.execute_input":"2024-08-25T17:19:37.468765Z","iopub.status.idle":"2024-08-25T17:19:50.309440Z","shell.execute_reply.started":"2024-08-25T17:19:37.468730Z","shell.execute_reply":"2024-08-25T17:19:50.308348Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:19:50.310943Z","iopub.execute_input":"2024-08-25T17:19:50.311267Z","iopub.status.idle":"2024-08-25T17:20:07.593789Z","shell.execute_reply.started":"2024-08-25T17:19:50.311233Z","shell.execute_reply":"2024-08-25T17:20:07.592634Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\nDownloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.3\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\n# Store the Hugging Face token in environment\nos.environ[\"HF_TOKEN\"] = \"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\"","metadata":{"id":"0v3ZZyZ_JxQY","execution":{"iopub.status.busy":"2024-08-25T17:20:07.596475Z","iopub.execute_input":"2024-08-25T17:20:07.596921Z","iopub.status.idle":"2024-08-25T17:20:07.601777Z","shell.execute_reply.started":"2024-08-25T17:20:07.596872Z","shell.execute_reply":"2024-08-25T17:20:07.600837Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=os.getenv(\"HF_TOKEN\"))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5P5URPJnJxWY","outputId":"7f346b2a-df7d-45d4-9916-a8f6e6d12bba","execution":{"iopub.status.busy":"2024-08-25T17:20:07.602917Z","iopub.execute_input":"2024-08-25T17:20:07.603260Z","iopub.status.idle":"2024-08-25T17:20:08.157242Z","shell.execute_reply.started":"2024-08-25T17:20:07.603220Z","shell.execute_reply":"2024-08-25T17:20:08.156334Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import LlamaForCausalLM, LlamaTokenizer, AutoModelForCausalLM\n","metadata":{"id":"GQlXsmM9HBpx","execution":{"iopub.status.busy":"2024-08-25T17:20:08.158318Z","iopub.execute_input":"2024-08-25T17:20:08.158610Z","iopub.status.idle":"2024-08-25T17:20:12.681773Z","shell.execute_reply.started":"2024-08-25T17:20:08.158578Z","shell.execute_reply":"2024-08-25T17:20:12.681022Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = LlamaForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397,"referenced_widgets":["ee9785c5854142d7933dbfd9ac142f2e","77e4c612921f491786af7a215c2e596e","2c9882eee9be4f7ba63345a53840acd6","0816a47c2c464602af3d53b21440c186","32e8d05cf71b4465b34691857a7eeebb","d220c5b9bf524503937720bd21572fa7","5cc168454a564154aa6343cd539e5436","d8d03a3b8d7940b8b1f728c5f1352517","ec5e34fd788e448f9cd7d6b2618b618e","5b096b0270d845ab98e855cdf66d0416","5e3c8328a0034d9fac096aafdabc0823","76ebeb1ea40a4d279357684e3256ad82","84714dac019d4c2ebce66e1dd0bb7aec","d093a71ade5745eb82eefbb46341e69f","f5ac70e3860146cb9b29d587fcf476af","4d2dcbfa6a194d91832b019143635f29","36cbc3e4f5e641faa092a5db2fb8dca2","9b129be6bf9f4c39bbc5c34a3d0b6c79","275d0d217aa7446482c55c80adec33d1","c16b6b31f57a495fae648bffaebe1ab8","1b11229b81264628ae7b1ff1519cf1a5","1b9689cce3d34fa99d1fac6ac5878670","f56246c9167a419d8b8fc95b98a1e1b5","e06819eb98e34ec0b60948622808ad84","634e8431341e4a58bfbe36c7e89fb35c","5a86067244004bd6b21abb9e49b71372","9cdfc7d424854bf18d1f692503e04a81","fece3a4097f74a2cbc7b5693998f1d6c","454e544864144b33b68d92a46ca3f9c3","9073c10462684a4ca1c6a1cc2a91348a","22d30563341d4d0cb34cee9859fe3513","66c3578e93d54a2cbe1a07472b658fa6","4c1249e4851243df837526f140567ade","781f570d5b9d4c829573f21159ef7298","a5b5ff5f367d493fb14656c0cb570a6e","80400f3c1881436f911240a97ab02de3","73e5debc1d5c4af0bff6982d46aec803","cbe30ca483294239ac26ab65f528fd68","d6e3dfd797664e3aae8802a99277fb2f","d49ef38528774710bfd601053a2619a3","f30db82fd312415a83c1f25d94cd5520","c37cba18726a4a5eb8841dab8ee704ce","b53a008e70ca402d8b444f6e9538d593","3e5841ae1f2d43b181cdac88f823d864","7e97afbe064c4107827bff7a83ee23af","b8cd787abbf5472aa67343f1728c52be","b98a14487fa54be6b21cb98710f0236e","2ae4c9fc31e24444ad8fde69774ef4d6","1f4f85e7258641738744a47cc7830ab1","7ca36631b7de4214816e8de83f62bd54","3f072af7153944ba82b063eefe35649c","84cf6a8f366a4209bb131f15dc43f873","aa33e97e580d4a6a9e2dac4fd0650e3a","574ff011085b47c79bc013db6124f126","a918b0a9b38c4beda735c4428b7010d7","4d3d09eaed5c45ba84863cdc5d4d0d6c","63ca1f8e6cb94d8b865c74ced85861c7","011b3613800e43cbaf638e8e6a583bd8","c96dd120454c44fcafee1552273bbbed","62b70c7b9e1340a0afe4b4bbffffcc1a","4a50dc563ffa4d9ebe48f0ad247bf120","c2e7ed8d29b147cbafde42fff242d6eb","4acf7c65d83040a7badda4f9d3fbc67d","87bc1eebc7d04e61b5f3ebe9087a07ec","d0f821e23a0a47b3bb94938a0648f433","f398c252e2794c9b98641af5f0e4ee9c","bc58e71ae35b488499f065323cb1fe29","9ceac8cd1f884506bf7ca1d33552f544","14de3ab8a7494fd1bcf859c3e4175608","04853163ef624248b3f57568861a21cb","6024583c2dbc4c08a0a0c04fa060d048","9a13efa683c843598fa744ce58cb12f7","65ae181635274d4c880e934a3a0a4408","fb34fe6fc6bc4f84a0f59f66a47721ad","a2c56562202c46ce9432a36239ecdcae","b2c59a1f051c409d9d6253347eb95250","5fcad3a172ef44bdb92c023116629f1d","1a22ba937b814709a4aa650cea645336","73de0d9cbb1046409fbfbdf54067e6a3","8158b8d7e1ea4965aa58e1b52e73c54d","583edc9ad23046f5a5f82412b45390d4","43eba5723e8f492e964d97b0ed11dbb0","fb35822cc9ad4264b5ffce02e1decd1e","caf5f164cd6d4376b2385e1d3d55a1c5","9df350b54a06477eb7713e39158317bb","090391f6875240969315c0de70c0c047","3664acc6a0d8451a8fcbaeb71befc9f5","0b1e3fd229814ec9a66904fa8075e58e"]},"id":"FhGOAGbdHHTg","outputId":"bea83fd1-e48c-4c4d-f1ad-4f73e7a312e6","execution":{"iopub.status.busy":"2024-08-25T16:53:29.559925Z","iopub.execute_input":"2024-08-25T16:53:29.560257Z","iopub.status.idle":"2024-08-25T16:56:06.070639Z","shell.execute_reply.started":"2024-08-25T16:53:29.560230Z","shell.execute_reply":"2024-08-25T16:56:06.069657Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Downloading shards: 100%|██████████| 4/4 [02:32<00:00, 38.07s/it]\nLoading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:20:12.683059Z","iopub.execute_input":"2024-08-25T17:20:12.683584Z","iopub.status.idle":"2024-08-25T17:20:12.691197Z","shell.execute_reply.started":"2024-08-25T17:20:12.683539Z","shell.execute_reply":"2024-08-25T17:20:12.690449Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")","metadata":{"execution":{"iopub.status.busy":"2024-08-25T16:56:06.078876Z","iopub.execute_input":"2024-08-25T16:56:06.079132Z","iopub.status.idle":"2024-08-25T16:56:06.992075Z","shell.execute_reply.started":"2024-08-25T16:56:06.079104Z","shell.execute_reply":"2024-08-25T16:56:06.991079Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Add a custom padding token\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:24:09.800297Z","iopub.execute_input":"2024-08-25T17:24:09.800606Z","iopub.status.idle":"2024-08-25T17:24:09.807586Z","shell.execute_reply.started":"2024-08-25T17:24:09.800573Z","shell.execute_reply":"2024-08-25T17:24:09.806656Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"markdown","source":"# Benchmark Functions","metadata":{"id":"-lBz_R-JUL7z"}},{"cell_type":"code","source":"def calculate_mmlu_zero_shot(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, return_attention_mask=True)\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=120)\n    return outputs\n\ndef calculate_mmlu_pro_five_shot(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, return_attention_mask=True)\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=120, num_return_sequences=5)\n    return outputs\n\ndef calculate_human_eval_zero_shot(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, return_attention_mask=True)\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=120)\n    return outputs\n\ndef calculate_mbpp_eval_zero_shot(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, return_attention_mask=True)\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=120)\n    return outputs\n\ndef calculate_if_eval_zero_shot(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, return_attention_mask=True)\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=120)\n    return outputs\n\ndef calculate_gsm8k_eight_shot(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, return_attention_mask=True)\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=120, num_return_sequences=8)\n    return outputs\n\ndef calculate_math_zero_shot(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, return_attention_mask=True)\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=120)\n    return outputs\n\ndef calculate_arc_challenge_zero_shot(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, return_attention_mask=True)\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=120)\n    return outputs\n\ndef calculate_gpqa_zero_shot(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, return_attention_mask=True)\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=120)\n    return outputs\n\n# attention_mask tells the model which tokens in the input sequence are actual data and which are just padding\n# The padding argument ensures that all sequences in a batch are of the same length, which is necessary for efficient processing in models that handle batches of data.\n# truncation argument ensures that input sequences do not exceed a maximum length that the model can handle.","metadata":{"id":"zlKivuIZJOfg","execution":{"iopub.status.busy":"2024-08-25T17:28:03.417863Z","iopub.execute_input":"2024-08-25T17:28:03.418274Z","iopub.status.idle":"2024-08-25T17:28:03.434362Z","shell.execute_reply.started":"2024-08-25T17:28:03.418233Z","shell.execute_reply":"2024-08-25T17:28:03.433476Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Prompt for each Benchmark","metadata":{"id":"5ERSeTteUUj_"}},{"cell_type":"code","source":"prompts = {\n\"MMLU (0-shot, CoT)\": \"Davis decided to kill Adams. He set out for Adams's house. Before he got there he saw Brooks, who resembled Adams. Thinking that Brooks was Adams, Davis shot at Brooks. The shot missed Brooks but wounded Case, who was some distance away. Davis had not seen Case. In a prosecution under a statute that proscribes any attempt to commit murder, the district attorney should indicate that the intended victim(s) was/were?\",\n\"MMLU PRO (5-shot, CoT)\": \"The symmetric group $S_n$ has $ \\factorial{n}$ elements, hence it is not true that $S_{10}$ has 10 elements. Find the characteristic of the ring 2Z.\",\n\"HumanEval (0-shot)\": \"Write a Python function to calculate the factorial of a given number.\",\n\"MBPP EvalPlus (Base)(0-shot)\": \"Write a function to find the longest chain which can be formed from the given set of pairs.\",\n\"IFEval Code (0-shot)\": \"Write a JavaScript function to validate an email address.\",\n\"GSM8K (8-shot)\": \"Generate eight different math word problems for 4th-grade level.\",\n\"Math (0-shot) (CoT)\": \"Solve the equation 2x + 5 = 11 and explain the steps.\",\n\"ARC Challenge (0-shot)\": \"Which interaction within an ecosystem is characterized by gradual change from one community of organisms to another?\",#NLP type Qs\n\"GPQA (0-shot, CoT)\": \"trans-cinnamaldehyde was treated with methylmagnesium bromide, forming product 1. 1 was treated with pyridinium chlorochromate, forming product 2. 3 was treated with (dimethyl(oxo)-l6-sulfaneylidene)methane in DMSO at elevated temperature, forming product 3. how many carbon atoms are there in product 3?.\"\n}","metadata":{"id":"AeN0rUtcUZnh","execution":{"iopub.status.busy":"2024-08-25T17:28:04.705855Z","iopub.execute_input":"2024-08-25T17:28:04.706249Z","iopub.status.idle":"2024-08-25T17:28:04.712175Z","shell.execute_reply.started":"2024-08-25T17:28:04.706213Z","shell.execute_reply":"2024-08-25T17:28:04.711284Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Calculate benchmarks non-quantized one","metadata":{"id":"n2tEamuHUdNa"}},{"cell_type":"code","source":"\n\noriginal_benchmarks = {}\noriginal_outputs = {}\n\nfor name, prompt in prompts.items():\n    if \"MMLU\" in name:\n        if \"5-shot\" in name:\n            outputs = calculate_mmlu_pro_five_shot(prompt)\n        else:\n            outputs = calculate_mmlu_zero_shot(prompt)\n    elif \"HumanEval\" in name:\n        outputs = calculate_human_eval_zero_shot(prompt)\n    elif \"MBPP\" in name:\n        outputs = calculate_mbpp_eval_zero_shot(prompt)\n    elif \"IFEval\" in name:\n        outputs = calculate_if_eval_zero_shot(prompt)\n    elif \"GSM8K\" in name:\n        outputs = calculate_gsm8k_eight_shot(prompt)\n    elif \"Math\" in name:\n        outputs = calculate_math_zero_shot(prompt)\n    elif \"ARC\" in name:\n        outputs = calculate_arc_challenge_zero_shot(prompt)\n    elif \"GPQA\" in name:\n        outputs = calculate_gpqa_zero_shot(prompt)\n\n    original_benchmarks[name] = outputs\n    original_outputs[name] = tokenizer.decode(outputs[0], skip_special_tokens=True)  # Store the decoded outputs\n\n# Store original benchmarks and outputs for comparison later\nprint(\"Original Benchmarks:\\n\", original_benchmarks)\nprint(\"\\nOriginal Outputs:\\n\", original_outputs)\n\n\n#import torch\n# # Ensure the tensor is defined before using it\n# try:\n#     # Define the tensor (example tensor provided)\n#     tensor = torch.tensor(outputs, dtype=torch.long)\n\n#     # Convert tensor to float before calculating the mean\n#     tensor_float = tensor.float()\n#     mean_value = tensor_float.mean()\n\n#     print(\"Mean value:\", mean_value)\n\n# except UnboundLocalError as e:\n#     print(f\"Error: {e}. Make sure the tensor is properly initialized.\")\n\n\n# # Function to extract and summarize benchmark values\n# def summarize_benchmarks(benchmarks):\n#     summarized = {}\n#     for key, value in benchmarks.items():\n#     # Assuming 'tensor' is your input tensor\n#         tensor = torch.tensor(outputs, dtype=torch.float)\n#         tensor_float = tensor.float()\n#         mean_value = tensor_float.mean()\n\n#         summarized[key] = torch.mean(value).item()  # Example: using mean to summarize\n#     return summarized\n\n# # Assuming 'original_benchmarks' is the dictionary containing all the tensor outputs\n# summarized_benchmarks = summarize_benchmarks(original_benchmarks)\n\n# # Print the summarized benchmarks\n# print(\"Summarized Benchmarks:\")\n# for key, value in summarized_benchmarks.items():\n#     print(f\"{key}: {value}\")\n#     print(\"\\nOriginal Outputs:\\n\", original_outputs)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:10:50.887292Z","iopub.execute_input":"2024-08-25T17:10:50.887768Z","iopub.status.idle":"2024-08-25T17:15:37.104160Z","shell.execute_reply.started":"2024-08-25T17:10:50.887732Z","shell.execute_reply":"2024-08-25T17:15:37.103247Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Original Benchmarks:\n {'MMLU (0-shot, CoT)': tensor([[128000,  97284,   6773,    311,   5622,  27329,     13,   1283,    743,\n            704,    369,  27329,    596,   3838,     13,  13538,    568,   2751,\n           1070,    568,   5602,  39119,     11,    889,  96858,  27329,     13,\n          53389,    430,  39119,    574,  27329,     11,  17200,   6689,    520,\n          39119,     13,    578,   6689,  13942,  39119,    719,  28593,  11799,\n             11,    889,    574,   1063,   6138,   3201,     13,  17200,   1047,\n            539,   3970,  11799,     13,    763,    264,  32699,   1234,    264,\n          35786,    430,   8882,  56236,    904,   4879,    311,   5379,  10102,\n             11,    279,   9474,  14065,   1288,  13519,    430,    279,  10825,\n          11996,   1161,      8,    574,   6458,    486,     30,    720,     32,\n              8,  39119,    198,     33,      8,  39119,    323,  11799,    198,\n             34,      8,    423,      8,  11799,    198,     35,      8,  27329,\n            271,    791,   1888,   4320,    374,    423,     13,    220,    578,\n          35786,    374,  15910]]), 'MMLU PRO (5-shot, CoT)': tensor([[128000,    791,  55443,   1912,    400,     50,   1107,      3,    706,\n            400,    220,    200,   5739,    532,  92462,  32816,   5540,     11,\n          16472,    433,    374,    539,    837,    430,    400,     50,  15511,\n            605,  32816,    706,    220,    605,   5540,     13,   7531,    279,\n          29683,    315,    279,  10264,    220,     17,     57,     13,    578,\n          29683,    315,    264,  10264,    374,    279,  25655,   6928,   7698,\n            308,   1778,    430,    400,     77,     59,  51953,    220,     16,\n            284,    220,     15,      3,   1405,    220,     16,    374,    279,\n          12842,  66366,   9764,    315,    279,  10264,     13,    763,    420,\n           1162,     11,    279,  12842,  66366,   9764,    315,    220,     17,\n             57,    374,    220,     17,     11,    323,    400,     17,     59,\n          51953,    220,     17,    284,    220,     19,   1144,    818,     80,\n            220,     15,      3,    304,    220,     17,     57,     11,    779,\n            279,  29683,    315],\n        [128000,    791,  55443,   1912,    400,     50,   1107,      3,    706,\n            400,    220,    200,   5739,    532,  92462,  32816,   5540,     11,\n          16472,    433,    374,    539,    837,    430,    400,     50,  15511,\n            605,  32816,    706,    220,    605,   5540,     13,   7531,    279,\n          29683,    315,    279,  10264,    220,     17,     57,     13,    578,\n          29683,    315,    264,  10264,    374,    279,  25655,   6928,   7698,\n            308,   1778,    430,    308,   3115,    220,     15,  17239,    220,\n             15,     13,   1102,    374,   1101,    279,  25655,   6928,   7698,\n            308,   1778,    430,    308,   3115,    904,   2449,    315,    279,\n          10264,    374,   6273,    311,    220,     15,     13,    578,  29683,\n            315,    279,  10264,    220,     17,     57,    374,    220,     17,\n           1606,    220,     17,   3115,    220,     16,    374,    220,     17,\n            902,    374,    539,   6273,    311,    220,     15,     11,    719,\n            220,     17,   3115],\n        [128000,    791,  55443,   1912,    400,     50,   1107,      3,    706,\n            400,    220,    200,   5739,    532,  92462,  32816,   5540,     11,\n          16472,    433,    374,    539,    837,    430,    400,     50,  15511,\n            605,  32816,    706,    220,    605,   5540,     13,   7531,    279,\n          29683,    315,    279,  10264,    220,     17,     57,     13,    220,\n             17,     57,    374,    279,  10264,    315,    682,   1524,  26864,\n             13,    578,  29683,    315,    264,  10264,    374,    279,  25655,\n           6928,   7698,    400,     77,      3,   1778,    430,    400,     77,\n           1144,  51953,    264,    284,    220,     15,      3,    369,    682,\n            400,     64,      3,    304,    279,  10264,     11,    477,    220,\n             15,    422,    912,   1778,   7698,   6866,     13,  14636,     11,\n            279,  29683,    315,    220,     17,     57,    374,    220,     17,\n             13,    220,     17,     57,    374,    279,  10264,    315,    682,\n           1524,  26864,     13],\n        [128000,    791,  55443,   1912,    400,     50,   1107,      3,    706,\n            400,    220,    200,   5739,    532,  92462,  32816,   5540,     11,\n          16472,    433,    374,    539,    837,    430,    400,     50,  15511,\n            605,  32816,    706,    220,    605,   5540,     13,   7531,    279,\n          29683,    315,    279,  10264,    220,     17,     57,     13,    578,\n          10264,    220,     17,     57,    374,    279,    743,    315,    682,\n           1524,  26864,     11,    902,    374,    264,   1081,    332,   1413,\n          10264,    449,   9764,     13,   1226,   1440,    430,    279,  29683,\n            315,    264,  10264,    374,    279,  25655,   6928,   7698,    400,\n             77,      3,   1778,    430,    400,     77,     59,  51953,    220,\n             16,    284,    220,     15,  55976,    477,    433,    374,   7315,\n            422,    912,   1778,    400,     77,      3,   6866,     13,    763,\n            279,  10264,    220,     17,     57,     11,    584,    617,    400,\n             17,     59,  51953],\n        [128000,    791,  55443,   1912,    400,     50,   1107,      3,    706,\n            400,    220,    200,   5739,    532,  92462,  32816,   5540,     11,\n          16472,    433,    374,    539,    837,    430,    400,     50,  15511,\n            605,  32816,    706,    220,    605,   5540,     13,   7531,    279,\n          29683,    315,    279,  10264,    220,     17,     57,     13,    320,\n          28085,     25,    578,  29683,    315,    264,  10264,    374,    279,\n          25655,   6928,   7698,    400,     77,      3,   1778,    430,    400,\n             77,     59,  51953,    220,     16,    284,    220,     15,      3,\n            570,    220,     16,      8,    220,     17,    220,     17,      8,\n            220,     19,    220,     18,      8,    220,     23,    220,     19,\n              8,    220,    845,    198,    567,  15166,    220,     16,     25,\n          71994,    279,   7434,    315,  29683,    315,    264,  10264,    198,\n            791,  29683,    315,    264,  10264,    374,    279,  25655,   6928,\n           7698,    308,   1778]]), 'HumanEval (0-shot)': tensor([[128000,   8144,    264,  13325,    734,    311,  11294,    279,  54062,\n            315,    264,   2728,   1396,     13,    578,  54062,    315,    264,\n           2536,  62035,   7698,    308,     11,   3453,   9437,    555,    308,\n          17581,    374,    279,   2027,    315,    682,   6928,  26864,   2753,\n           1109,    477,   6273,    311,    308,     13,   1789,   3187,     11,\n            220,     20,      0,    284,    220,     20,      9,     19,      9,\n             18,      9,     17,      9,     16,    284,    220,   4364,    382,\n            567,  15166,    220,     16,     25,  19127,    279,    734,    449,\n            264,   5852,    369,    279,   1988,   1396,    198,   1687,    690,\n           1893,    264,    734,   2663,   1595,  38691,    532,     63,    430,\n           5097,    459,   7698,   1595,     77,     63,    439,   1988,    382,\n            567,  15166,    220,     17,     25,   9185,    279,   1121,   3977,\n            198,   1687,    690,   9656,    264,   3977,   1595,   1407,     63,\n            311,    220,     16]]), 'MBPP EvalPlus (Base)(0-shot)': tensor([[128000,   8144,    264,    734,    311,   1505,    279,  22807,   8957,\n            902,    649,    387,  14454,    505,    279,   2728,    743,    315,\n          13840,     13,   9062,   6857,  11105,    264,   3465,    430,    649,\n            387,   2884,    304,    264,   3738,    892,     13,    578,   3465,\n            449,    279,  22807,   8250,   1288,    387,  12146,   1176,    382,\n           8586,    374,    279,   7419,    315,    279,   3575,   1473,  22818,\n            264,    743,    315,  13840,     11,   1505,    279,  22807,   8957,\n            315,   9256,    430,    649,    387,   2884,    304,    279,   2728,\n            892,    382,  13617,    512,   2566,     25,   9256,    284,  18305,\n             18,     11,    220,    605,    705,    320,     16,     11,    220,\n             17,    705,    320,     17,     11,    220,     19,   5680,   5207,\n             25,    220,    605,    271,  70869,    512,    791,  22807,   8957,\n            315,   9256,    649,    387,  14454,    555,  19301,    279,   9256,\n            449,  90204,    220]]), 'IFEval Code (0-shot)': tensor([[128000,   8144,    264,  13210,    734,    311,   9788,    459,   2613,\n           2686,     13,   1115,    734,   1288,   1817,    422,    279,   2613,\n           2686,   5727,   2225,    459,  97948,    323,    264,  23600,    323,\n            422,    433,   5727,    264,  97948,    433,   1288,   1817,    422,\n            433,   5727,    264,  23600,   1603,    279,  97948,    323,   1306,\n            279,  97948,    382,   8586,    374,    459,   3187,    315,   1268,\n            279,    734,   1436,    387,   1511,   1473,  74694,  14402,    198,\n           5467,   1699,  95344,   4886,    446,   8858,  36587,    916,  33696,\n            220,    443,   4780,    837,    198,   5467,   1699,  95344,   4886,\n            446,   8858,  36587,  33696,    220,    443,   4780,    905,    198,\n           5467,   1699,  95344,   4886,    446,   8858,    916,  33696,    220,\n            443,   4780,    905,    198,   5467,   1699,  95344,   4886,    446,\n           8858,  33696,    220,    443,   4780,    905,    198,  14196,  19884,\n           8586,    374,    264]]), 'GSM8K (8-shot)': tensor([[128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   4314,   3492,   5435,   1288,\n           3504,   5369,     11,  76340,     11,  47544,     11,    323,  13096,\n          19476,     13,   9062,   3492,   3575,   1288,    387,   5016,    323,\n            539,  59177,    627,     16,     13,   8529,    706,    220,    868,\n          97438,    304,    813,  47218,   1162,     13,   1283,  21879,    220,\n             22,    810,  97438,    439,    264,   8352,    505,    813,   4333,\n             13,   2650,   1690,  97438,   1587,   8529,    617,   1457,   1980,\n          16533,     25,    220,   1313,    271,     17,     13,    362,   2363,\n          55050,    706,    220,     20,  36310,     11,    323,   1855,  28745,\n            649,   3412,    220,     23,   6603,     13,   2650,   1690,   6603,\n            649,    279,   2363,  55050,   3412,    304,   2860,   1980,  16533,\n             25,    220,   1272,    271,     18,     13,  21077,    706,    220,\n            972,  90016,   2439],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3575,   1288,    387,\n            264,   1972,  31184,  15398,    430,  18065,   7447,  49442,  47544,\n             11,  13096,     11,    477,   5369,  38985,  27523,     13,  30834,\n            279,   2768,   3649,    304,   1855,   3575,   1473,      9,    256,\n            362,   2867,  15398,    430,    264,    220,     19,    339,  25313,\n           1013,    649,   3619,    198,      9,    256,    362,   3230,   3488,\n            477,   3575,    311,    387,  29056,    198,      9,    256,    362,\n          35876,   4320,    430,    649,    387,  16997,   1701,   6913,   7033,\n           7677,    271,   8586,    527,   8223,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,   1473,     16,     13,    220,   3146,\n          32298,    220,     16,     25,   1035,    262,    362,   2363,  55050,\n            706,    220,     20,  36310,     11,    323,   1855,  28745,    649,\n           3412,    220,     23],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3492,   3575,   1288,\n           2997,    279,   2768,   5540,    512,      9,    362,   2867,    323,\n          64694,   3488,    198,      9,    362,   9959,    323,   7185,  15398,\n            198,      9,    362,  37072,   5784,    320,    723,    684,     11,\n          76340,     11,  47544,     11,    477,  13096,      8,    430,   7612,\n           4236,    311,   3881,    872,   8830,    315,    279,   7434,    198,\n              9,    362,   6425,    430,   7612,   4236,    311,   3881,    872,\n           8830,    315,    279,   7434,    311,  17782,    520,    264,  13579,\n           4320,    271,   8586,    527,   8223,   2204,   7033,   3492,   5435,\n            369,    220,     19,    339,  41327,   2237,   1473,     16,     13,\n            220,   3146,  32298,  68063,   8529,    706,    220,    868,  97438,\n            304,    813,  47218,   1162,     13,   1283,   6835,    220,     18,\n          97438,    311,    813],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3492,   3575,   1288,\n            387,   5552,    311,    832,    315,    279,   2768,  13650,     25,\n          47544,     11,  13096,     11,  65995,     11,  59428,     11,  17484,\n             11,  19179,     11,    892,     11,    477,   3300,     13,    578,\n           3492,   5435,   1288,    387,   2867,     11,  64694,     11,    323,\n          17436,    369,    220,     19,    339,  41327,   4236,    382,    567,\n          15166,    220,     16,     25,   4324,    264,  47544,   3492,   3575,\n            198,  25763,    706,    220,     18,   5315,    315,    220,     21,\n          97438,   1855,     13,   2650,   1690,  97438,   1587,   8529,    617,\n            304,   2860,   1980,    567,  15166,    220,     17,     25,   4324,\n            264,  13096,   3492,   3575,    198,     32,   2363,  55050,    706,\n            220,    972,   6603,    389,    433,     11,    323,    814,   1205,\n            311,    387,  19937],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3492,   3575,   1288,\n           2997,    264,   6651,    315,   5369,     11,  76340,     11,  47544,\n             11,    323,  13096,   7677,     13,   4815,    567,  15166,    220,\n             16,     25,   4324,   3492,   3575,    220,     16,    369,   5369,\n            198,  25763,    706,    220,    868,  97438,    304,    813,  47218,\n           1162,     13,   5414,   4333,   6835,   1461,    220,     22,    810,\n          97438,     13,   2650,   1690,  97438,   1587,   8529,    617,   1457,\n           1980,    567,  15166,    220,     17,     25,   4324,   3492,   3575,\n            220,     17,    369,  76340,    198,  54183,    706,    220,    914,\n          50396,    304,   1077,   4526,     13,   3005,   6835,    220,     23,\n          50396,    311,   1077,  10868,     13,   2650,   1690,  50396,   1587,\n          21077,    617,   2163,   1980,    567,  15166,    220,     18,     25,\n           4324,   3492,   3575],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3575,   1288,   2997,\n            279,   2768,   5540,   1473,     16,     13,    220,    362,  15398,\n            477,   2317,    430,    374,   1375,  15436,    323,  23387,    369,\n            220,     19,    339,  41327,   4236,    627,     17,     13,    220,\n            362,  37072,   5784,    320,    723,    684,     11,  76340,     11,\n          47544,     11,    477,  13096,      8,    430,    374,   9959,    311,\n            279,  15398,    627,     18,     13,    220,    362,   3230,  35876,\n            907,    477,   2819,    430,    527,   1511,    304,    279,   3575,\n            627,     19,     13,    220,    362,   3488,    430,   7612,    279,\n           5575,    311,  11886,    279,   3575,    323,   3493,    264,  35876,\n           4320,    382,   8586,    527,   8223,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,   1473,     16,     13,    220,   3146,\n          32298,    220,     16],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3575,   1288,    617,\n            264,   6425,    430,  18065,    264,  12395,     13,   1789,   3187,\n             11,    264,   3575,   2643,   2610,   4236,    311,   1505,    279,\n           2860,   2853,    315,   3673,    430,   2853,    400,     18,     13,\n           1135,     11,    400,     17,     13,    914,     11,    323,    400,\n             16,     13,   2075,     11,    477,    311,  11294,    279,   3158,\n            315,    264,  23596,    449,  15696,    220,     20,     13,     17,\n          10166,    555,    220,     18,     13,     23,  10166,    382,    567,\n          15166,    220,     16,     25,   4324,    264,   3492,   3575,  16239,\n            279,   2853,    315,   3673,    627,  25763,    706,    400,    868,\n             13,    410,    311,   8493,    520,    279,   2978,   3637,     13,\n           1283,  50631,    264,  47218,    369,    400,     18,     13,   1135,\n             11,    264,  38266],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3575,   1288,    387,\n            264,   6651,    315,   5369,     11,  76340,     11,  47544,     11,\n            323,  13096,     11,    323,   1288,   2997,    264,   1972,  31184,\n          15398,    627,   8586,    527,   8223,   7033,   3492,   5435,    369,\n            220,     19,    339,  41327,   2237,   1473,     16,     13,   8529,\n            706,    220,    868,  97438,    304,    813,  47218,   1162,     13,\n           1283,  11621,    220,     22,    810,  97438,    311,    433,     13,\n           2650,   1690,  97438,   1587,   8529,    617,   1457,   1980,     17,\n             13,    362,   2363,  55050,    706,    220,    717,   6603,    389,\n            433,     13,   1442,    220,     19,    810,   6603,    527,   3779,\n             11,   1268,   1690,   6603,    690,    387,    389,    279,   2363,\n          55050,    304,   2860,   1980,     18,     13,    362,  66244,  31878,\n            220,    972,  88993]]), 'Math (0-shot) (CoT)': tensor([[128000,     50,   4035,    279,  24524,    220,     17,     87,    489,\n            220,     20,    284,    220,    806,    323,  10552,    279,   7504,\n             13,  52050,   8468,    220,     16,     25,  94310,    220,     20,\n            505,   2225,  11314,    315,    279,  24524,    198,     17,     87,\n            489,    220,     20,    482,    220,     20,    284,    220,    806,\n            482,    220,     20,    198,     17,     87,    284,    220,     21,\n            198,   8468,    220,     17,     25,  64002,   2225,  11314,    315,\n            279,  24524,    555,    220,     17,    198,      7,     17,     87,\n           5738,     17,    284,    220,     21,     14,     17,    198,     87,\n            284,    220,     18,    198,    791,   1620,   4320,    374,     25,\n          59060,  80175,     90,     18,  32816,    662,  52050,   2028,   3575,\n          18065,  22581,    264,  13790,  24524,    449,    264,   3254,   3977,\n             13,    578,   7504,    311,  11886,    279,  24524,    527,    439,\n          11263,    512,   8468]]), 'ARC Challenge (0-shot)': tensor([[128000,  23956,  16628,   2949,    459,  26031,    374,  32971,    555,\n          53722,   2349,    505,    832,   4029,    315,  44304,    311,   2500,\n             30,    220,     16,     13,  67754,  91260,    220,     17,     13,\n           4255,    367,    220,     18,     13,  50953,  50787,    220,     19,\n             13,  27848,   2191,    198,    567,  15166,    220,     16,     25,\n          71994,    279,  17931,    315,   1855,   4751,   2728,    304,    279,\n           2671,    627,     12,    328,   3437,  91260,  19813,    311,    264,\n           3345,    323,   3629,   1317,   9860,   5133,   1990,   2204,  24156,\n           9606,     11,    902,    649,    387,  27848,   4633,    320,  68244,\n           7235,    311,   2225,    705,   1081,    729,    278,    320,  68244,\n           7235,    311,    832,     11,  21277,    311,    279,   1023,    705,\n            477,  33403,  49086,    320,  68244,   7235,    311,    832,     11,\n          28856,    311,    279,   1023,   4390,     12,  30924,    367,    374,\n            264,   5133,   1990]]), 'GPQA (0-shot, CoT)': tensor([[128000,   1485,   1824,   6258,    309,    278,  86836,    574,  12020,\n            449,  79574,     76,   3326,  41930,  94571,    579,     11,  30164,\n           2027,    220,     16,     13,    220,     16,    574,  12020,    449,\n           4611,   1907,  64990,  37833,   5059,    442,    349,     11,  30164,\n           2027,    220,     17,     13,    220,     18,    574,  12020,    449,\n            320,  13223,  42972,      7,   5241,     78,   7435,     75,     21,\n           1355,  14643,  82286,  62306,   1994,  47707,    774,   2194,    304,\n            423,   4931,     46,    520,  32389,   9499,     11,  30164,   2027,\n            220,     18,     13,   1268,   1690,  12782,  33299,    527,   1070,\n            304,   2027,    220,     18,   4710,    220,     19,    574,  12020,\n            449,    264,   3831,   2385,     11,  30164,   2027,    220,     19,\n             13,    220,     20,    574,  12020,    449,    264,   3831,  13935,\n             11,  30164,   2027,    220,     20,     13,   1268,   1690,  12782,\n          33299,    527,   1070]])}\n\nOriginal Outputs:\n {'MMLU (0-shot, CoT)': \"Davis decided to kill Adams. He set out for Adams's house. Before he got there he saw Brooks, who resembled Adams. Thinking that Brooks was Adams, Davis shot at Brooks. The shot missed Brooks but wounded Case, who was some distance away. Davis had not seen Case. In a prosecution under a statute that proscribes any attempt to commit murder, the district attorney should indicate that the intended victim(s) was/were? \\nA) Brooks\\nB) Brooks and Case\\nC) D) Case\\nD) Adams\\n\\nThe best answer is D.  The statute is directed\", 'MMLU PRO (5-shot, CoT)': 'The symmetric group $S_n$ has $ \\x0cactorial{n}$ elements, hence it is not true that $S_{10}$ has 10 elements. Find the characteristic of the ring 2Z. The characteristic of a ring is the smallest positive integer n such that $n\\\\cdot 1 = 0$ where 1 is the multiplicative identity of the ring. In this case, the multiplicative identity of 2Z is 2, and $2\\\\cdot 2 = 4 \\\\neq 0$ in 2Z, so the characteristic of', 'HumanEval (0-shot)': 'Write a Python function to calculate the factorial of a given number. The factorial of a non-negative integer n, denoted by n!, is the product of all positive integers less than or equal to n. For example, 5! = 5*4*3*2*1 = 120.\\n\\n## Step 1: Define the function with a parameter for the input number\\nWe will create a function called `factorial` that takes an integer `n` as input.\\n\\n## Step 2: Initialize the result variable\\nWe will initialize a variable `result` to 1', 'MBPP EvalPlus (Base)(0-shot)': 'Write a function to find the longest chain which can be formed from the given set of pairs. Each pair represents a task that can be done in a certain time. The task with the longest duration should be chosen first.\\n\\nHere is the definition of the problem:\\n\\nGiven a set of pairs, find the longest chain of tasks that can be done in the given time.\\n\\nExample:\\nInput: tasks = [(3, 10), (1, 2), (2, 4)]\\nOutput: 10\\n\\nExplanation:\\nThe longest chain of tasks can be formed by choosing the tasks with durations ', 'IFEval Code (0-shot)': 'Write a JavaScript function to validate an email address. This function should check if the email address contains both an \"@\" and a \".\" and if it contains a \"@\" it should check if it contains a \".\" before the \"@\" and after the \"@\".\\n\\nHere is an example of how the function could be used:\\n\\n```javascript\\nconsole.log(validateEmail(\"example@example.com\"));  // returns true\\nconsole.log(validateEmail(\"example@example\"));  // returns false\\nconsole.log(validateEmail(\"example.com\"));  // returns false\\nconsole.log(validateEmail(\"example\"));  // returns false\\n```\\n\\nHere is a', 'GSM8K (8-shot)': 'Generate eight different math word problems for 4th-grade level. These word problems should cover addition, subtraction, multiplication, and division concepts. Each word problem should be unique and not repetitive.\\n1. Tom has 15 pencils in his pencil case. He receives 7 more pencils as a gift from his friend. How many pencils does Tom have now?\\n\\nAnswer: 22\\n\\n2. A bookshelf has 5 shelves, and each shelf can hold 8 books. How many books can the bookshelf hold in total?\\n\\nAnswer: 40\\n\\n3. Sarah has 18 crayons', 'Math (0-shot) (CoT)': 'Solve the equation 2x + 5 = 11 and explain the steps.\\xa0\\nStep 1: Subtract 5 from both sides of the equation\\n2x + 5 - 5 = 11 - 5\\n2x = 6\\nStep 2: Divide both sides of the equation by 2\\n(2x)/2 = 6/2\\nx = 3\\nThe final answer is: $\\\\boxed{3}$.\\xa0\\nThis problem involves solving a linear equation with a single variable. The steps to solve the equation are as follows:\\nStep', 'ARC Challenge (0-shot)': 'Which interaction within an ecosystem is characterized by gradual change from one community of organisms to another? 1. symbiosis 2. predation 3. ecological succession 4. mutualism\\n## Step 1: Understand the definitions of each term given in the options.\\n- Symbiosis refers to a close and often long-term relationship between different biological species, which can be mutualistic (beneficial to both), commensal (beneficial to one, neutral to the other), or parasitic (beneficial to one, harmful to the other).\\n- Predation is a relationship between', 'GPQA (0-shot, CoT)': 'trans-cinnamaldehyde was treated with methylmagnesium bromide, forming product 1. 1 was treated with pyridinium chlorochromate, forming product 2. 3 was treated with (dimethyl(oxo)-l6-sulfaneylidene)methane in DMSO at elevated temperature, forming product 3. how many carbon atoms are there in product 3?. 4 was treated with a strong base, forming product 4. 5 was treated with a strong acid, forming product 5. how many carbon atoms are there'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Quantization","metadata":{}},{"cell_type":"code","source":"# from transformers import BitsAndBytesConfig, LlamaForCausalLM, LlamaTokenizer\n\n# # Quantization configuration (4-bit quantization)\n# quant_config = BitsAndBytesConfig(load_in_4bit=True)\n\n# Load the quantized model\n# quantized_model = LlamaForCausalLM.from_pretrained(\n#     \"meta-llama/Meta-Llama-3.1-8B\",\n#     quantization_config=quant_config,\n#     device_map=\"auto\"\n#)\n\nmodel = LlamaForCausalLM.from_pretrained(\"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\")\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:20:25.473241Z","iopub.execute_input":"2024-08-25T17:20:25.473641Z","iopub.status.idle":"2024-08-25T17:24:09.798825Z","shell.execute_reply.started":"2024-08-25T17:20:25.473604Z","shell.execute_reply":"2024-08-25T17:24:09.797992Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.45k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce734ff319cf48e5a0647e3322e32996"}},"metadata":{}},{"name":"stderr","text":"Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59b9e4ae713e4f5b8e8fdd79943a9721"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62447b4de1454350abf8f6ffd73035b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5079d0d8f4b8460d904de213a7f618dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"891178ee1ee44b8e81c5123e3f5d79f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/340 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb6221e2674e40f3b2e5ff91dc869799"}},"metadata":{}}]},{"cell_type":"code","source":"def calculate_benchmarks_quantized(model, tokenizer, prompts):\n    quantized_benchmarks = {}\n    outputs_dict = {}  # To store the generated outputs\n\n    for name, prompt in prompts.items():\n        if \"MMLU\" in name:\n            if \"5-shot\" in name:\n                outputs = calculate_mmlu_pro_five_shot(prompt)\n            else:\n                outputs = calculate_mmlu_zero_shot(prompt)\n        elif \"HumanEval\" in name:\n            outputs = calculate_human_eval_zero_shot(prompt)\n        elif \"MBPP\" in name:\n            outputs = calculate_mbpp_eval_zero_shot(prompt)\n        elif \"IFEval\" in name:\n            outputs = calculate_if_eval_zero_shot(prompt)\n        elif \"GSM8K\" in name:\n            outputs = calculate_gsm8k_eight_shot(prompt)\n        elif \"Math\" in name:\n            outputs = calculate_math_zero_shot(prompt)\n        elif \"ARC\" in name:\n            outputs = calculate_arc_challenge_zero_shot(prompt)\n        elif \"GPQA\" in name:\n            outputs = calculate_gpqa_zero_shot(prompt)\n\n        quantized_benchmarks[name] = outputs\n        outputs_dict[name] = tokenizer.decode(outputs[0], skip_special_tokens=True)  # Decode and store outputs\n\n    return quantized_benchmarks, outputs_dict\n\n# Run benchmarks on the quantized model\nquantized_benchmarks, quantized_outputs = calculate_benchmarks_quantized(model, tokenizer, prompts)\n\n# Print the benchmarks and outputs\nprint(\"Quantized Benchmarks:\\n\", quantized_benchmarks)\nprint(\"\\nQuantized Outputs:\\n\", quantized_outputs)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T17:28:13.128990Z","iopub.execute_input":"2024-08-25T17:28:13.129637Z","iopub.status.idle":"2024-08-25T17:30:46.016733Z","shell.execute_reply.started":"2024-08-25T17:28:13.129601Z","shell.execute_reply":"2024-08-25T17:30:46.015693Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1885: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1885: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Quantized Benchmarks:\n {'MMLU (0-shot, CoT)': tensor([[128000,  97284,   6773,    311,   5622,  27329,     13,   1283,    743,\n            704,    369,  27329,    596,   3838,     13,  13538,    568,   2751,\n           1070,    568,   5602,  39119,     11,    889,  96858,  27329,     13,\n          53389,    430,  39119,    574,  27329,     11,  17200,   6689,    520,\n          39119,     13,    578,   6689,  13942,  39119,    719,  28593,  11799,\n             11,    889,    574,   1063,   6138,   3201,     13,  17200,   1047,\n            539,   3970,  11799,     13,    763,    264,  32699,   1234,    264,\n          35786,    430,   8882,  56236,    904,   4879,    311,   5379,  10102,\n             11,    279,   9474,  14065,   1288,  13519,    430,    279,  10825,\n          11996,   1161,      8,    574,   6458,    486,     30,    320,     32,\n              8,   1193,  27329,     11,    320,     33,      8,   1193,  39119,\n             11,    320,     34,      8,  27329,    323,  39119,     11,    320,\n             35,      8,   1193,  11799,     11,    320,     36,      8,  27329,\n            323,  11799,    627]]), 'MMLU PRO (5-shot, CoT)': tensor([[128000,    791,  55443,   1912,    400,     50,   1107,      3,    706,\n            400,    220,    200,   5739,    532,  92462,  32816,   5540,     11,\n          16472,    433,    374,    539,    837,    430,    400,     50,  15511,\n            605,  32816,    706,    220,    605,   5540,     13,   7531,    279,\n          29683,    315,    279,  10264,    220,     17,     57,     13,    220,\n             17,     57,    374,    264,  10264,    315,  26864,    315,    279,\n           1376,    220,     17,     74,     11,   1405,    597,    374,    459,\n           7698,     13,    578,  29683,    315,    264,  10264,    374,    279,\n          25655,   6928,   7698,    308,   1778,    430,    308,   3115,    904,\n           2449,    315,    279,  10264,    374,   7315,     13,    763,    420,\n           1162,     11,    584,    617,    430,    220,     17,   3115,    904,\n           2449,    315,    220,     17,     57,    374,   7315,     11,    779,\n            279,  29683,    315,    220,     17,     57,    374,    220,     17,\n            627,  19918,  22559],\n        [128000,    791,  55443,   1912,    400,     50,   1107,      3,    706,\n            400,    220,    200,   5739,    532,  92462,  32816,   5540,     11,\n          16472,    433,    374,    539,    837,    430,    400,     50,  15511,\n            605,  32816,    706,    220,    605,   5540,     13,   7531,    279,\n          29683,    315,    279,  10264,    220,     17,     57,     13,    220,\n             17,     57,    374,    264,  10264,    449,   5540,    220,     15,\n             11,    220,     17,     11,    220,     19,     11,    220,     21,\n             11,    220,     23,     13,    578,  29683,    374,    279,  25655,\n           6928,   7698,    308,   1778,    430,    308,    374,    459,   2449,\n            315,    279,  10264,     13,    578,  29683,    315,    279,  10264,\n            220,     17,     57,    374,    220,     17,    627,    791,  29683,\n            315,    264,  10264,    374,    279,  25655,   6928,   7698,   1778,\n            430,   1070,    374,    264,  10264,   2449,    902,    374,    264,\n           5361,    315,    430],\n        [128000,    791,  55443,   1912,    400,     50,   1107,      3,    706,\n            400,    220,    200,   5739,    532,  92462,  32816,   5540,     11,\n          16472,    433,    374,    539,    837,    430,    400,     50,  15511,\n            605,  32816,    706,    220,    605,   5540,     13,   7531,    279,\n          29683,    315,    279,  10264,    220,     17,     57,     13,    578,\n          29683,    315,    279,  10264,    220,     17,     57,    374,    279,\n          25655,   6928,   7698,    308,   1778,    430,    308,   1144,  51953,\n            220,     16,    284,    220,     15,    304,    279,  10264,     13,\n           8876,    220,     17,   1144,  51953,    220,     16,    284,    220,\n             15,    304,    279,  10264,    220,     17,     57,     11,    279,\n          29683,    315,    279,  10264,    220,     17,     57,    374,    220,\n             17,     13,   7531,    279,  29683,    315,    279,  10264,    220,\n             18,     57,     13,    578,  29683,    315,    279,  10264,    220,\n             18,     57,    374],\n        [128000,    791,  55443,   1912,    400,     50,   1107,      3,    706,\n            400,    220,    200,   5739,    532,  92462,  32816,   5540,     11,\n          16472,    433,    374,    539,    837,    430,    400,     50,  15511,\n            605,  32816,    706,    220,    605,   5540,     13,   7531,    279,\n          29683,    315,    279,  10264,    220,     17,     57,     13,    578,\n          29683,    315,    264,  10264,    374,   4613,    439,    279,  25655,\n           6928,   7698,    400,     77,      3,   1778,    430,    400,     77,\n             59,  51953,    220,     16,    284,    220,     15,      3,   1405,\n            400,     16,      3,    374,    279,  12842,  66366,   9764,    315,\n            279,  10264,     13,    763,    279,  10264,    220,     17,     57,\n             11,    279,  12842,  66366,   9764,    374,    220,     17,    323,\n            400,     77,     59,  51953,    220,     16,    284,    220,     15,\n              3,    994,    400,     77,      3,    374,   1524,     13,  14636,\n             11,    279,  29683],\n        [128000,    791,  55443,   1912,    400,     50,   1107,      3,    706,\n            400,    220,    200,   5739,    532,  92462,  32816,   5540,     11,\n          16472,    433,    374,    539,    837,    430,    400,     50,  15511,\n            605,  32816,    706,    220,    605,   5540,     13,   7531,    279,\n          29683,    315,    279,  10264,    220,     17,     57,     13,    220,\n             18,     57,     13,    220,     20,     57,     13,    220,     22,\n             57,     13,    220,    806,     57,     13,    220,   1032,     57,\n             13,    220,   1114,     57,     13,    220,    777,     57,     13,\n            220,   1419,     57,     13,    220,   1682,     57,     13,    220,\n           2148,     57,     13,    220,   1806,     57,     13,    220,   3174,\n             57,     13,    220,   3391,     57,     13,    220,   2618,     57,\n             13,    220,   4331,     57,     13,    220,   2946,     57,     13,\n            220,   5547,     57,     13,    220,   3080,     57,     13,    220,\n           6028,     57,     13]]), 'HumanEval (0-shot)': tensor([[128000,   8144,    264,  13325,    734,    311,  11294,    279,  54062,\n            315,    264,   2728,   1396,     13,    578,    734,   1288,   1935,\n            459,   7698,    439,   1988,    323,    471,    279,  54062,    315,\n            430,   7698,     13,   1442,    279,   1988,    374,    539,    264,\n           2536,  62035,   7698,     11,    279,    734,   1288,   4933,    264,\n          15764,    382,  74694,  12958,    198,    755,  54062,   1471,    997,\n            262,   3270,    262,  21157,    279,  54062,    315,    264,   2728,\n           1396,    382,    262,  18161,    512,    286,    308,    320,    396,\n           1680,    578,   1396,    311,  11294,    279,  54062,    315,    382,\n            262,   5295,    512,    286,    528,     25,    578,  54062,    315,\n            279,   2728,   1396,    382,    262,  61411,    512,    286,  15764,\n             25,   1442,    279,   1988,    374,    539,    264,   2536,  62035,\n           7698,    627,    262,   3270,    262,    422,    539,  11656,   1471,\n             11,    528,    997]]), 'MBPP EvalPlus (Base)(0-shot)': tensor([[128000,   8144,    264,    734,    311,   1505,    279,  22807,   8957,\n            902,    649,    387,  14454,    505,    279,   2728,    743,    315,\n          13840,     13,    362,   6857,  17610,    315,   1403,  26864,    902,\n           4097,    279,   1212,    323,    842,   3585,    315,    459,   6964,\n            304,    264,   4876,     13,    362,   8957,    374,    264,   8668,\n            315,  13116,   1405,   1475,   6964,  34161,   1403,  17672,    304,\n            279,   3766,   8668,     13,    362,   2764,   8957,   2011,    539,\n           6782,    904,  11008,    382,  13617,    512,   2566,     25,  13840,\n            284,  18305,     16,     11,    220,     17,    705,    320,     17,\n             11,    220,     18,    705,    320,     18,     11,    220,     19,\n            705,    320,     16,     11,    220,     18,    705,    320,     16,\n             11,    220,     19,    705,    320,     19,     11,    220,     20,\n           5680,   5207,     25,    220,     17,    198,  70869,     25,    578,\n          22807,   8957,    374]]), 'IFEval Code (0-shot)': tensor([[128000,   8144,    264,  13210,    734,    311,   9788,    459,   2613,\n           2686,     13,    578,    734,   1288,    471,    837,    422,    279,\n           2613,   2686,    374,   2764,     11,    323,    905,   6062,    382,\n          74694,  14402,    198,   1723,   9788,   4886,  18411,      8,    341,\n            262,    443,  19127,    279,   5497,    369,    264,   2764,   2613,\n           2686,    198,    262,    738,   5497,    284,  76436,     64,  21768,\n          11419,     15,     12,     24,   1462,      4,  22192,   7727,  41260,\n             64,  21768,  11419,     15,     12,     24,  12898,  67427,   8032,\n             64,  21768,  11419,  15731,     17,     11,  70253,    280,   1084,\n            262,    443,   5560,    279,   1296,   1749,    311,   1817,    422,\n            279,   2613,   9248,    279,   5497,    198,    262,    471,   5497,\n           6085,  18411,    317,    633,    322,  13688,  10648,    512,   5467,\n           1699,  95344,   4886,    446,   1985,  36587,    916,  33696,    220,\n            443,  32121,   2612]]), 'GSM8K (8-shot)': tensor([[128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3492,   3575,   1288,\n            617,    264,   2204,   5784,    320,    723,    684,     11,  76340,\n             11,  47544,     11,  13096,      8,    323,   2997,    264,   9302,\n          13340,    320,  27581,    477,  13861,      8,    311,   1520,   4236,\n           3619,    279,   3575,    382,   8586,    527,   8223,   3492,   5435,\n            369,    220,     19,    339,  41327,   2237,   1473,     16,     13,\n           3146,   2261,    684,   1035,   9789,     25,    362,   6945,    315,\n            264,  24623,   4680,   6201,    449,    220,    868,  19289,    323,\n            264,   4333,   7999,    220,     22,    810,  19289,    627,  32298,\n             25,    330,  25763,   2465,    706,    220,    868,  19289,    304,\n            813,  24623,   4680,   6201,     13,   5414,   4333,   6835,   1461,\n            220,     22,    810,  19289,     13,   2650,   1690,  19289,   1587,\n          40139,    617,   1457],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3492,   3575,   1288,\n            387,   3196,    389,    264,   2204,  37072,   5784,    320,    723,\n            684,     11,  76340,     11,  47544,     11,    477,  13096,   4390,\n           8586,    527,   8223,   7033,   3492,   5435,    369,    220,     19,\n            339,  41327,   2237,     11,   1855,   3196,    389,    264,   2204,\n          37072,   5784,   1473,     16,     13,   3146,   2261,    684,   1035,\n          25763,    706,    220,    868,  97438,    304,    813,  47218,   1162,\n             13,   5414,   4333,   6835,   1461,    220,     22,    810,  97438,\n             13,   2650,   1690,  97438,   1587,   8529,    617,   1457,   1980,\n             17,     13,   3146,   3214,  27523,   1035,     32,   2363,  55050,\n            706,    220,    914,   6603,    389,    433,     13,   1442,    220,\n             23,   6603,    527,   7108,     11,   1268,   1690,   6603,    527,\n           2163,    389,    279],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3492,   3575,   1288,\n            387,   3196,    389,    264,   2204,   5784,    320,    723,    684,\n             11,  76340,     11,  47544,     11,    477,  13096,      8,    323,\n           2997,    264,   9302,  13340,    315,    279,   3575,     13,   5560,\n            279,   4495,  37072,   5784,    323,   3493,    279,   6425,    311,\n           1855,   3575,    382,    567,  15166,    220,     16,     25,   4324,\n            264,   3492,   3575,    369,   5369,    198,  25763,    706,    220,\n            868,  97438,    304,    813,  47218,   1162,     13,   5414,   4333,\n           6835,   1461,    220,     22,    810,  97438,     13,   2650,   1690,\n          97438,   1587,   8529,    617,   1457,   1980,    567,  15166,    220,\n             17,     25,   4324,    264,   3492,   3575,    369,  76340,    198,\n          54183,    706,    220,    914,  50396,    304,   1077,  47277,   2363,\n             13,   3005,   6835],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3492,   3575,   1288,\n            617,    264,   6425,    430,    649,    387,  13605,    439,    264,\n          19983,     13,   5810,    527,    279,   3492,   5435,   1473,     16,\n             13,   8529,    706,    220,     16,     14,     19,    315,    264,\n          23317,   2163,    927,   1306,  11821,    433,    449,    813,   4885,\n             13,   1442,    568,   6944,    311,   3665,    220,     16,     14,\n             21,    315,    279,   9861,  23317,    369,  16986,     11,   1268,\n           1790,    315,    279,   4113,  23317,    690,    568,    617,   2163,\n           1980,     17,     13,    362,   2363,  55050,    706,    220,     18,\n             14,     19,    315,   1202,   3634,  10409,    449,   6603,     13,\n           1442,    220,     16,     14,     18,    315,    279,   6603,    527,\n          32963,     11,   1148,  19983,    315,    279,   2363,  55050,    374,\n          10409,    449,  32963],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3492,   3575,   1288,\n            617,    264,   2204,   5784,    320,    723,    684,     11,  76340,\n             11,  47544,     11,    477,  13096,      8,    323,    264,   2204,\n           2317,    320,     68,   1326,   2637,   3300,     11,    892,     11,\n          19179,     11,   5099,  36434,   5810,    527,    279,   3492,   5435,\n           1473,     16,     13,   3146,   2261,    684,   9805,     25,  18099,\n           1035,  25763,    706,    400,    868,    304,    813,  24623,   4680,\n           6201,     13,   5414,  83777,   6835,   1461,    400,     23,    439,\n            264,   8352,     13,   5414,   3450,  11621,    400,    717,    810,\n            369,    813,  15553,     13,   2650,   1790,   3300,   1587,   8529,\n            617,   1457,   1980,     17,     13,   3146,   3214,  27523,   9805,\n             25,   4212,   1035,     32,   5818,   8638,    520,    220,     17,\n           5975,    323,  40758],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,    578,   5435,   1288,  21736,\n           7447,  49442,   5219,    323,    279,   3116,   6913,   7033,   7677,\n            320,    723,    684,     11,  76340,     11,  47544,     11,    323,\n          13096,    570,   9062,   3575,   1288,    387,   5016,    323,    539,\n          13454,    904,   7677,    477,   5219,    382,   8586,    527,   8223,\n           2204,   3492,   5435,    369,    220,     19,    339,  41327,   2237,\n           1473,     16,     13,    220,   3146,   2261,    684,   1035,    256,\n          21077,    706,    220,  10961,  97438,    304,   1077,  47218,   1162,\n             13,   6385,   4333,   6835,   1077,    220,  16949,    810,  97438,\n             13,   2650,   1690,  97438,   1587,  21077,    617,   1457,   1980,\n             17,     13,    220,   3146,   3214,  27523,   1035,    256,    362,\n           2363,  55050,    706,    220,  24599,   6603,    389,    433,     13,\n           1442,    220,  16718],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   9062,   3492,   3575,   1288,\n          21736,  47544,    323,  13096,     13,   5810,    527,    279,   3492,\n           5435,   1473,     16,     13,    362,   2363,  55050,    706,    220,\n             20,  36310,     11,    323,   1855,  28745,    649,   3412,    220,\n             23,   6603,     13,   1442,    279,   2363,  55050,    374,   5131,\n           4384,     11,   1268,   1690,   6603,    649,    387,   9277,    389,\n            433,    304,   2860,   1980,     17,     13,    362,   1912,    315,\n           4885,   1390,    311,   4430,   1063,  32656,  18813,     13,   1442,\n            814,    617,    220,   2166,   9863,    315,  32656,    323,   1070,\n            527,    220,     21,   4885,     11,   1268,   1690,   9863,    315,\n          32656,    690,   1855,   4333,    636,   1980,     18,     13,    362,\n          37500,    706,    220,    717,  69444,    315,  41776,     11,    323,\n           1855,  14351,   5727],\n        [128000,  32215,   8223,   2204,   7033,   3492,   5435,    369,    220,\n             19,    339,  41327,   2237,     13,   4314,   3492,   5435,   1288,\n            387,   5552,    311,    279,   8712,    315,  65995,     11,    323,\n            814,   1288,   1397,   4236,    311,   3881,    872,   8830,    315,\n          13890,  65995,     11,  27393,  65995,     11,    323,  34537,   1990,\n           9709,   5219,    323,  41086,  65995,     13,   5810,    527,   8223,\n           3492,   5435,    369,    220,     19,    339,  41327,   2237,   1473,\n             16,     13,    220,  35266,    706,    220,     16,     14,     19,\n            315,    264,  23317,    430,   1364,   6944,    311,   4430,    449,\n           1077,   4333,     13,   1442,   1364,   6835,    220,     16,     14,\n             23,    315,    279,  23317,    311,   1077,   4333,     11,   1148,\n          19983,    315,    279,  23317,   1587,  35266,    617,   2163,   1980,\n             17,     13,    220,    362,  11363,   6880,    369,    220,     18,\n             14,     19,  10747]]), 'Math (0-shot) (CoT)': tensor([[128000,     50,   4035,    279,  24524,    220,     17,     87,    489,\n            220,     20,    284,    220,    806,    323,  10552,    279,   7504,\n             13,  52050,   8468,    220,     16,     25,   9842,   1523,    279,\n          24524,    198,     17,     87,    489,    220,     20,    284,    220,\n            806,    198,   8468,    220,     17,     25,  94310,    220,     20,\n            505,   2225,  11314,    315,    279,  24524,    198,     17,     87,\n            489,    220,     20,   1389,    220,     20,    284,    220,    806,\n           1389,    220,     20,    198,   2028,  15858,   9803,    311,    220,\n             17,     87,    284,    220,     21,    198,   8468,    220,     18,\n             25,  64002,   2225,  11314,    315,    279,  24524,    555,    220,\n             17,    198,      7,     17,     87,      8,    611,    220,     17,\n            284,    220,     21,    611,    220,     17,    198,   2028,  15858,\n           9803,    311,    865,    284,    220,     18,    198,   8468,    220,\n             19,     25,   9842]]), 'ARC Challenge (0-shot)': tensor([[128000,  23956,  16628,   2949,    459,  26031,    374,  32971,    555,\n          53722,   2349,    505,    832,   4029,    315,  44304,    311,   2500,\n             30,    362,      8,   4255,    367,    426,      8,  10937,    356,\n              8,  17028,    367,    423,      8,  27848,   2191,    198,  16533,\n             25,    426,    198,  70869,     25,  17375,  33949,    374,    459,\n          16628,    304,    902,    832,   9606,    320,   1820,  17028,    859,\n              8,   7720,   2500,   9606,    320,   1820,  63932,      8,    555,\n           6968,    459,   4676,    304,    902,    279,  63932,    649,   3974,\n             13,  30924,    367,    374,    459,  16628,    304,    902,    832,\n           9606,    320,   1820,  68006,      8,  50777,   2500,   9606,    320,\n           1820,  37693,    570,  42321,    374,    459,  16628,    304,    902,\n           1403,    477,    810,   9606,  17536,    369,    279,   1890,   5211,\n             13,  75142,   2191,    374,    459,  16628,    304,    902,   1403,\n            477,    810,   9606]]), 'GPQA (0-shot, CoT)': tensor([[128000,   1485,   1824,   6258,    309,    278,  86836,    574,  12020,\n            449,  79574,     76,   3326,  41930,  94571,    579,     11,  30164,\n           2027,    220,     16,     13,    220,     16,    574,  12020,    449,\n           4611,   1907,  64990,  37833,   5059,    442,    349,     11,  30164,\n           2027,    220,     17,     13,    220,     18,    574,  12020,    449,\n            320,  13223,  42972,      7,   5241,     78,   7435,     75,     21,\n           1355,  14643,  82286,  62306,   1994,  47707,    774,   2194,    304,\n            423,   4931,     46,    520,  32389,   9499,     11,  30164,   2027,\n            220,     18,     13,   1268,   1690,  12782,  33299,    527,   1070,\n            304,   2027,    220,     18,   4710,  22559,     25,    220,    508,\n            198,    567,  15166,    220,     16,     25,    220,   5629,     11,\n            584,   1205,    311,   3619,    279,  11742,  25481,   7633,    304,\n            279,   3575,    323,  10765,    279,   1401,  54070,    323,    279,\n           1620,   2027,    627]])}\n\nQuantized Outputs:\n {'MMLU (0-shot, CoT)': \"Davis decided to kill Adams. He set out for Adams's house. Before he got there he saw Brooks, who resembled Adams. Thinking that Brooks was Adams, Davis shot at Brooks. The shot missed Brooks but wounded Case, who was some distance away. Davis had not seen Case. In a prosecution under a statute that proscribes any attempt to commit murder, the district attorney should indicate that the intended victim(s) was/were? (A) only Adams, (B) only Brooks, (C) Adams and Brooks, (D) only Case, (E) Adams and Case.\\n\", 'MMLU PRO (5-shot, CoT)': 'The symmetric group $S_n$ has $ \\x0cactorial{n}$ elements, hence it is not true that $S_{10}$ has 10 elements. Find the characteristic of the ring 2Z. 2Z is a ring of integers of the form 2k, where k is an integer. The characteristic of a ring is the smallest positive integer n such that n times any element of the ring is zero. In this case, we have that 2 times any element of 2Z is zero, so the characteristic of 2Z is 2.\\nFinal Answer', 'HumanEval (0-shot)': 'Write a Python function to calculate the factorial of a given number. The function should take an integer as input and return the factorial of that integer. If the input is not a non-negative integer, the function should raise a ValueError.\\n\\n```python\\ndef factorial(n):\\n    \"\"\"\\n    Calculate the factorial of a given number.\\n\\n    Args:\\n        n (int): The number to calculate the factorial of.\\n\\n    Returns:\\n        int: The factorial of the given number.\\n\\n    Raises:\\n        ValueError: If the input is not a non-negative integer.\\n    \"\"\"\\n    if not isinstance(n, int):\\n', 'MBPP EvalPlus (Base)(0-shot)': 'Write a function to find the longest chain which can be formed from the given set of pairs. A pair consists of two integers which represent the start and end points of an edge in a graph. A chain is a sequence of edges where every edge connects two vertices in the previous sequence. A valid chain must not contain any cycle.\\n\\nExample:\\nInput: pairs = [(1, 2), (2, 3), (3, 4), (1, 3), (1, 4), (4, 5)]\\nOutput: 2\\nExplanation: The longest chain is', 'IFEval Code (0-shot)': 'Write a JavaScript function to validate an email address. The function should return true if the email address is valid, and false otherwise.\\n\\n```javascript\\nfunction validateEmail(email) {\\n    // Define the pattern for a valid email address\\n    const pattern = /^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}$/;\\n    \\n    // Use the test method to check if the email matches the pattern\\n    return pattern.test(email);\\n}\\n\\n// Example usage:\\nconsole.log(validateEmail(\"test@example.com\"));  // Expected output', 'GSM8K (8-shot)': 'Generate eight different math word problems for 4th-grade level. Each word problem should have a different operation (addition, subtraction, multiplication, division) and include a visual representation (picture or diagram) to help students understand the problem.\\n\\nHere are eight word problems for 4th-grade level:\\n\\n1. **Addition**\\nVisual: A picture of a piggy bank with 15 coins and a friend adding 7 more coins.\\nProblem: \"Tommy has 15 coins in his piggy bank. His friend gives him 7 more coins. How many coins does Tommy have now', 'Math (0-shot) (CoT)': 'Solve the equation 2x + 5 = 11 and explain the steps.\\xa0\\nStep 1: Write down the equation\\n2x + 5 = 11\\nStep 2: Subtract 5 from both sides of the equation\\n2x + 5 – 5 = 11 – 5\\nThis simplifies to 2x = 6\\nStep 3: Divide both sides of the equation by 2\\n(2x) / 2 = 6 / 2\\nThis simplifies to x = 3\\nStep 4: Write', 'ARC Challenge (0-shot)': 'Which interaction within an ecosystem is characterized by gradual change from one community of organisms to another? A) predation B) competition C) facilitation D) mutualism\\nAnswer: B\\nExplanation: Facilitation is an interaction in which one species (the facilitator) benefits another species (the beneficiary) by creating an environment in which the beneficiary can live. Predation is an interaction in which one species (the predator) eats another species (the prey). Competition is an interaction in which two or more species vie for the same resource. Mutualism is an interaction in which two or more species', 'GPQA (0-shot, CoT)': 'trans-cinnamaldehyde was treated with methylmagnesium bromide, forming product 1. 1 was treated with pyridinium chlorochromate, forming product 2. 3 was treated with (dimethyl(oxo)-l6-sulfaneylidene)methane in DMSO at elevated temperature, forming product 3. how many carbon atoms are there in product 3?. Answer: 20\\n## Step 1:  First, we need to understand the chemical reactions described in the problem and identify the key transformations and the final product.\\n'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Comparing both quantized & non-quantized Benchmarks","metadata":{}},{"cell_type":"code","source":"# Compare benchmarks\nfor name in prompts.keys():\n    print(f\"Benchmark: {name}\")\n    print(f\"Original: {original_benchmarks.get(name)}\")\n    print(f\"Quantized: {quantized_benchmarks.get(name)}\\n\")\n\n# Compare outputs\nfor name in prompts.keys():\n    print(f\"Output: {name}\")\n    print(f\"Original: {original_outputs.get(name)}\")\n    print(f\"Quantized: {quantized_outputs.get(name)}\\n\")\n","metadata":{},"execution_count":null,"outputs":[]}]}